{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 11:20:35.395453: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-11 11:20:35.567444: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-11 11:20:36.562148: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-03-11 11:20:36.562263: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-03-11 11:20:36.562276: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "from dataset_util import split_dataset\n",
    "\n",
    "\n",
    "def base_preprocess(image, label):\n",
    "    image = preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def preprocess(image, label):\n",
    "    image, label = base_preprocess(image, label)\n",
    "    thr = 0.005\n",
    "    label += thr\n",
    "    label = tf.clip_by_value(label, clip_value_min=0, clip_value_max=1 - thr * 9)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def gen_dataset(img_size, batch_size):\n",
    "    # split_dataset()\n",
    "\n",
    "    # データセットの読み込み\n",
    "    train_dataset = image_dataset_from_directory(\n",
    "        \"./Flowers/Train\",\n",
    "        image_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        label_mode=\"categorical\",  # クラス分類\n",
    "        shuffle=True,\n",
    "    )\n",
    "    train_dataset = train_dataset.map(preprocess)\n",
    "\n",
    "    val_dataset = image_dataset_from_directory(\n",
    "        \"./Flowers/Val\",\n",
    "        image_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        label_mode=\"categorical\",\n",
    "        shuffle=False,\n",
    "    )\n",
    "    val_dataset = val_dataset.map(base_preprocess)\n",
    "    return train_dataset, val_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 480 files belonging to 10 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 11:20:37.966992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-03-11 11:20:38.030126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-03-11 11:20:38.030383: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-03-11 11:20:38.031111: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-11 11:20:38.032216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-03-11 11:20:38.032440: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-03-11 11:20:38.032662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-03-11 11:20:38.111046: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-03-11 11:20:38.111269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-03-11 11:20:38.111457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-03-11 11:20:38.111634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1027 MB memory:  -> device: 0, name: NVIDIA A40-16C, pci bus id: 0000:00:05.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 files belonging to 10 classes.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 11:20:50.262098: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8907\n",
      "2025-03-11 11:20:50.299676: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-03-11 11:20:50.411821: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 11s 219ms/step - loss: 1.8626 - accuracy: 0.5229 - val_loss: 1.1231 - val_accuracy: 0.7667 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 0.8577 - accuracy: 0.8708 - val_loss: 0.7775 - val_accuracy: 0.8833 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.7179 - accuracy: 0.9417 - val_loss: 0.6670 - val_accuracy: 0.9083 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.6405 - accuracy: 0.9583 - val_loss: 0.6051 - val_accuracy: 0.9417 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.6412 - accuracy: 0.9646 - val_loss: 0.5700 - val_accuracy: 0.9667 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 1s 63ms/step - loss: 0.5970 - accuracy: 0.9771 - val_loss: 0.5541 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 0.5850 - accuracy: 0.9688 - val_loss: 0.5405 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 1s 62ms/step - loss: 0.5913 - accuracy: 0.9792 - val_loss: 0.5020 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 0.5893 - accuracy: 0.9750 - val_loss: 0.4744 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.5587 - accuracy: 0.9896 - val_loss: 0.4580 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.5380 - accuracy: 0.9917 - val_loss: 0.4388 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.5573 - accuracy: 0.9729 - val_loss: 0.4241 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.5366 - accuracy: 0.9917 - val_loss: 0.3996 - val_accuracy: 0.9667 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.5387 - accuracy: 0.9833 - val_loss: 0.3791 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.5341 - accuracy: 0.9875 - val_loss: 0.3710 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.5261 - accuracy: 0.9917 - val_loss: 0.3661 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 0.5006 - accuracy: 1.0000 - val_loss: 0.3653 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.5125 - accuracy: 0.9958 - val_loss: 0.3463 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 0.5150 - accuracy: 0.9937 - val_loss: 0.3279 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.5066 - accuracy: 0.9958 - val_loss: 0.3238 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.5155 - accuracy: 0.9875 - val_loss: 0.3128 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.4990 - accuracy: 0.9979 - val_loss: 0.3068 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 0.5016 - accuracy: 0.9917 - val_loss: 0.2975 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 0.4986 - accuracy: 0.9917 - val_loss: 0.2925 - val_accuracy: 0.9667 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 1s 62ms/step - loss: 0.4916 - accuracy: 0.9875 - val_loss: 0.2972 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 0.4917 - accuracy: 0.9979 - val_loss: 0.2889 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 1s 61ms/step - loss: 0.4963 - accuracy: 0.9917 - val_loss: 0.2842 - val_accuracy: 0.9667 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.4809 - accuracy: 1.0000 - val_loss: 0.2676 - val_accuracy: 0.9833 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.4838 - accuracy: 0.9958 - val_loss: 0.2611 - val_accuracy: 0.9833 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.4770 - accuracy: 0.9979 - val_loss: 0.2586 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.4808 - accuracy: 0.9937 - val_loss: 0.2651 - val_accuracy: 0.9833 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.4821 - accuracy: 0.9958 - val_loss: 0.2726 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 1s 61ms/step - loss: 0.4717 - accuracy: 0.9979 - val_loss: 0.2800 - val_accuracy: 0.9667 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 0.4720 - accuracy: 0.9958 - val_loss: 0.2748 - val_accuracy: 0.9667 - lr: 2.0000e-04\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.4714 - accuracy: 1.0000 - val_loss: 0.2708 - val_accuracy: 0.9667 - lr: 2.0000e-04\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 1s 61ms/step - loss: 0.4687 - accuracy: 0.9958 - val_loss: 0.2671 - val_accuracy: 0.9750 - lr: 2.0000e-04\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.4632 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9750 - lr: 4.0000e-05\n",
      "Epoch 37: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.applications import EfficientNetB1\n",
    "from keras import layers, models\n",
    "from keras.regularizers import l2\n",
    "\n",
    "# 画像のサイズ（EfficientNetの標準サイズに合わせる）\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "train_dataset, val_dataset = gen_dataset(input_shape[:2], 32)\n",
    "\n",
    "X_spec, y_spec = train_dataset.element_spec\n",
    "num_classes = y_spec.shape[1:][0]\n",
    "\n",
    "# モデルのベースを作成（事前学習済みの EfficientNetB0 を利用）\n",
    "base_model = EfficientNetB1(\n",
    "    weights=\"imagenet\", include_top=False, input_shape=input_shape\n",
    ")\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "model = models.Sequential(\n",
    "    [\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(128, activation=\"relu\", kernel_regularizer=l2(5e-4)),\n",
    "        layers.Dropout(0.5),  # 過学習を防ぐためにDropoutを追加\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),  # 10クラス分類\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=3, min_lr=1e-8)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=7, verbose=1, mode=\"min\"\n",
    ")\n",
    "\n",
    "H = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=50,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[reduce_lr, early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 files belonging to 10 classes.\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.4100 - accuracy: 0.9350\n",
      "Test Accuracy: 0.9350\n"
     ]
    }
   ],
   "source": [
    "img_size = (224, 224, 3)\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    \"./Test\",\n",
    "    image_size=img_size[:2],\n",
    "    batch_size=64,\n",
    "    label_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    ")\n",
    "test_dataset = test_dataset.map(base_preprocess)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
